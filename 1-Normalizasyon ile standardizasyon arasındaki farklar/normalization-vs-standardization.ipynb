{
 "metadata": {
  "kernelspec": {
   "language": "python",
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.10.12",
   "mimetype": "text/x-python",
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "pygments_lexer": "ipython3",
   "nbconvert_exporter": "python",
   "file_extension": ".py"
  },
  "kaggle": {
   "accelerator": "none",
   "dataSources": [],
   "dockerImageVersionId": 30626,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook",
   "isGpuEnabled": false
  }
 },
 "nbformat_minor": 4,
 "nbformat": 4,
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "Normalization and standardization are two common preprocessing techniques used in machine learning to scale and transform features. They are particularly useful when working with algorithms that are sensitive to the scale of input features, such as k-nearest neighbors or support vector machines."
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "Normalization scales the values of a feature to a range between 0 and 1."
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "source": [
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "# Sample data\n",
    "data = [[-1, 2], [-0.5, 6], [0, 10], [1, 18]]\n",
    "\n",
    "# Initialize the MinMaxScaler\n",
    "scaler = MinMaxScaler()\n",
    "\n",
    "# Fit and transform the data\n",
    "normalized_data = scaler.fit_transform(data)\n",
    "\n",
    "print(\"Normalized Data:\")\n",
    "print(normalized_data)"
   ],
   "metadata": {
    "execution": {
     "iopub.status.busy": "2023-12-30T12:17:47.505466Z",
     "iopub.execute_input": "2023-12-30T12:17:47.506391Z",
     "iopub.status.idle": "2023-12-30T12:17:48.721393Z",
     "shell.execute_reply.started": "2023-12-30T12:17:47.506355Z",
     "shell.execute_reply": "2023-12-30T12:17:48.720214Z"
    },
    "trusted": true,
    "ExecuteTime": {
     "end_time": "2023-12-30T12:26:54.906380Z",
     "start_time": "2023-12-30T12:26:41.330878Z"
    }
   },
   "execution_count": 1,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Normalized Data:\n",
      "[[0.   0.  ]\n",
      " [0.25 0.25]\n",
      " [0.5  0.5 ]\n",
      " [1.   1.  ]]\n"
     ]
    }
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "Standardization transforms the values of a feature so that they have a mean of 0 and a standard deviation of 1. "
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "# Sample data\n",
    "data = [[-1, 2], [-0.5, 6], [0, 10], [1, 18]]\n",
    "\n",
    "# Initialize the StandardScaler\n",
    "scaler = StandardScaler()\n",
    "\n",
    "# Fit and transform the data\n",
    "standardized_data = scaler.fit_transform(data)\n",
    "\n",
    "print(\"Standardized Data:\")\n",
    "print(standardized_data)\n"
   ],
   "metadata": {
    "execution": {
     "iopub.status.busy": "2023-12-30T12:17:48.722972Z",
     "iopub.execute_input": "2023-12-30T12:17:48.723338Z",
     "iopub.status.idle": "2023-12-30T12:17:48.733179Z",
     "shell.execute_reply.started": "2023-12-30T12:17:48.723298Z",
     "shell.execute_reply": "2023-12-30T12:17:48.731842Z"
    },
    "trusted": true
   },
   "execution_count": 2,
   "outputs": [
    {
     "name": "stdout",
     "text": "Standardized Data:\n[[-1.18321596 -1.18321596]\n [-0.50709255 -0.50709255]\n [ 0.16903085  0.16903085]\n [ 1.52127766  1.52127766]]\n",
     "output_type": "stream"
    }
   ]
  }
 ]
}
